{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/PRNU/data\n"
     ]
    }
   ],
   "source": [
    "cd data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.engine import InputSpec\n",
    "from keras.engine.topology import Layer\n",
    "from keras.layers import Input, Conv2D, Activation, BatchNormalization\n",
    "from keras.layers.merge import Add\n",
    "from keras.utils import conv_utils\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "\n",
    "def res_block(input, filters, kernel_size=(3, 3), strides=(1, 1), use_dropout=False):\n",
    "    \"\"\"\n",
    "    Instanciate a Keras Resnet Block using sequential API.\n",
    "    :param input: Input tensor\n",
    "    :param filters: Number of filters to use\n",
    "    :param kernel_size: Shape of the kernel for the convolution\n",
    "    :param strides: Shape of the strides for the convolution\n",
    "    :param use_dropout: Boolean value to determine the use of dropout\n",
    "    :return: Keras Model\n",
    "    \"\"\"\n",
    "    x = ReflectionPadding2D((1, 1))(input)\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    if use_dropout:\n",
    "        x = Dropout(0.5)(x)\n",
    "\n",
    "    x = ReflectionPadding2D((1, 1))(x)\n",
    "    x = Conv2D(filters=filters,\n",
    "               kernel_size=kernel_size,\n",
    "               strides=strides,)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    merged = Add()([input, x])\n",
    "    return merged\n",
    "\n",
    "\n",
    "def spatial_reflection_2d_padding(x, padding=((1, 1), (1, 1)), data_format=None):\n",
    "    \"\"\"\n",
    "    Pad the 2nd and 3rd dimensions of a 4D tensor.\n",
    "    :param x: Input tensor\n",
    "    :param padding: Shape of padding to use\n",
    "    :param data_format: Tensorflow vs Theano convention ('channels_last', 'channels_first')\n",
    "    :return: Tensorflow tensor\n",
    "    \"\"\"\n",
    "    assert len(padding) == 2\n",
    "    assert len(padding[0]) == 2\n",
    "    assert len(padding[1]) == 2\n",
    "    if data_format is None:\n",
    "        data_format = image_data_format()\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        raise ValueError('Unknown data_format ' + str(data_format))\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        pattern = [[0, 0],\n",
    "                   [0, 0],\n",
    "                   list(padding[0]),\n",
    "                   list(padding[1])]\n",
    "    else:\n",
    "        pattern = [[0, 0],\n",
    "                   list(padding[0]), list(padding[1]),\n",
    "                   [0, 0]]\n",
    "    return tf.pad(x, pattern, \"REFLECT\")\n",
    "\n",
    "\n",
    "# TODO: Credits\n",
    "class ReflectionPadding2D(Layer):\n",
    "    \"\"\"Reflection-padding layer for 2D input (e.g. picture).\n",
    "    This layer can add rows and columns or zeros\n",
    "    at the top, bottom, left and right side of an image tensor.\n",
    "    # Arguments\n",
    "        padding: int, or tuple of 2 ints, or tuple of 2 tuples of 2 ints.\n",
    "            - If int: the same symmetric padding\n",
    "                is applied to width and height.\n",
    "            - If tuple of 2 ints:\n",
    "                interpreted as two different\n",
    "                symmetric padding values for height and width:\n",
    "                `(symmetric_height_pad, symmetric_width_pad)`.\n",
    "            - If tuple of 2 tuples of 2 ints:\n",
    "                interpreted as\n",
    "                `((top_pad, bottom_pad), (left_pad, right_pad))`\n",
    "        data_format: A string,\n",
    "            one of `channels_last` (default) or `channels_first`.\n",
    "            The ordering of the dimensions in the inputs.\n",
    "            `channels_last` corresponds to inputs with shape\n",
    "            `(batch, height, width, channels)` while `channels_first`\n",
    "            corresponds to inputs with shape\n",
    "            `(batch, channels, height, width)`.\n",
    "            It defaults to the `image_data_format` value found in your\n",
    "            Keras config file at `~/.keras/keras.json`.\n",
    "            If you never set it, then it will be \"channels_last\".\n",
    "    # Input shape\n",
    "        4D tensor with shape:\n",
    "        - If `data_format` is `\"channels_last\"`:\n",
    "            `(batch, rows, cols, channels)`\n",
    "        - If `data_format` is `\"channels_first\"`:\n",
    "            `(batch, channels, rows, cols)`\n",
    "    # Output shape\n",
    "        4D tensor with shape:\n",
    "        - If `data_format` is `\"channels_last\"`:\n",
    "            `(batch, padded_rows, padded_cols, channels)`\n",
    "        - If `data_format` is `\"channels_first\"`:\n",
    "            `(batch, channels, padded_rows, padded_cols)`\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 padding=(1, 1),\n",
    "                 data_format=None,\n",
    "                 **kwargs):\n",
    "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
    "        self.data_format = conv_utils.normalize_data_format(data_format)\n",
    "        if isinstance(padding, int):\n",
    "            self.padding = ((padding, padding), (padding, padding))\n",
    "        elif hasattr(padding, '__len__'):\n",
    "            if len(padding) != 2:\n",
    "                raise ValueError('`padding` should have two elements. '\n",
    "                                 'Found: ' + str(padding))\n",
    "            height_padding = conv_utils.normalize_tuple(padding[0], 2,\n",
    "                                                        '1st entry of padding')\n",
    "            width_padding = conv_utils.normalize_tuple(padding[1], 2,\n",
    "                                                       '2nd entry of padding')\n",
    "            self.padding = (height_padding, width_padding)\n",
    "        else:\n",
    "            raise ValueError('`padding` should be either an int, '\n",
    "                             'a tuple of 2 ints '\n",
    "                             '(symmetric_height_pad, symmetric_width_pad), '\n",
    "                             'or a tuple of 2 tuples of 2 ints '\n",
    "                             '((top_pad, bottom_pad), (left_pad, right_pad)). '\n",
    "                             'Found: ' + str(padding))\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            if input_shape[2] is not None:\n",
    "                rows = input_shape[2] + self.padding[0][0] + self.padding[0][1]\n",
    "            else:\n",
    "                rows = None\n",
    "            if input_shape[3] is not None:\n",
    "                cols = input_shape[3] + self.padding[1][0] + self.padding[1][1]\n",
    "            else:\n",
    "                cols = None\n",
    "            return (input_shape[0],\n",
    "                    input_shape[1],\n",
    "                    rows,\n",
    "                    cols)\n",
    "        elif self.data_format == 'channels_last':\n",
    "            if input_shape[1] is not None:\n",
    "                rows = input_shape[1] + self.padding[0][0] + self.padding[0][1]\n",
    "            else:\n",
    "                rows = None\n",
    "            if input_shape[2] is not None:\n",
    "                cols = input_shape[2] + self.padding[1][0] + self.padding[1][1]\n",
    "            else:\n",
    "                cols = None\n",
    "            return (input_shape[0],\n",
    "                    rows,\n",
    "                    cols,\n",
    "                    input_shape[3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return spatial_reflection_2d_padding(inputs,\n",
    "                                             padding=self.padding,\n",
    "                                             data_format=self.data_format)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'padding': self.padding,\n",
    "                  'data_format': self.data_format}\n",
    "        base_config = super(ReflectionPadding2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Activation, Add\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.core import Lambda\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "ngf = 64\n",
    "input_nc = 3\n",
    "output_nc = 3\n",
    "input_shape_generator = (256, 256, input_nc)\n",
    "n_blocks_gen = 9\n",
    "\n",
    "\n",
    "def generator_model():\n",
    "    \"\"\"Build generator architecture.\"\"\"\n",
    "    # Current version : ResNet block\n",
    "    inputs = Input(shape=image_shape)\n",
    "\n",
    "    x = ReflectionPadding2D((3, 3))(inputs)\n",
    "    x = Conv2D(filters=ngf, kernel_size=(7,7), padding='valid')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Increase filter number\n",
    "    n_downsampling = 2\n",
    "    for i in range(n_downsampling):\n",
    "        mult = 2**i\n",
    "        x = Conv2D(filters=ngf*mult*2, kernel_size=(3,3), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    # Apply 9 ResNet blocks\n",
    "    mult = 2**n_downsampling\n",
    "    for i in range(n_blocks_gen):\n",
    "        x = res_block(x, ngf*mult, use_dropout=True)\n",
    "\n",
    "    # Decrease filter number to 3 (RGB)\n",
    "    for i in range(n_downsampling):\n",
    "        mult = 2**(n_downsampling - i)\n",
    "        x = Conv2DTranspose(filters=int(ngf * mult / 2), kernel_size=(3,3), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation('relu')(x)\n",
    "\n",
    "    x = ReflectionPadding2D((3,3))(x)\n",
    "    x = Conv2D(filters=output_nc, kernel_size=(7,7), padding='valid')(x)\n",
    "    x = Activation('tanh')(x)\n",
    "\n",
    "    # Add direct connection from input to output and recenter to [-1, 1]\n",
    "    outputs = Add()([x, inputs])\n",
    "    outputs = Lambda(lambda z: z/2)(outputs)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs, name='Generator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.core import Dense, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "ndf = 64\n",
    "output_nc = 3\n",
    "input_shape_discriminator = (256, 256, output_nc)\n",
    "\n",
    "\n",
    "def discriminator_model():\n",
    "    \"\"\"Build discriminator architecture.\"\"\"\n",
    "    n_layers, use_sigmoid = 3, False\n",
    "    inputs = Input(shape=input_shape_discriminator)\n",
    "\n",
    "    x = Conv2D(filters=ndf, kernel_size=(4,4), strides=2, padding='same')(inputs)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    nf_mult, nf_mult_prev = 1, 1\n",
    "    for n in range(n_layers):\n",
    "        nf_mult_prev, nf_mult = nf_mult, min(2**n, 8)\n",
    "        x = Conv2D(filters=ndf*nf_mult, kernel_size=(4,4), strides=2, padding='same')(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    nf_mult_prev, nf_mult = nf_mult, min(2**n_layers, 8)\n",
    "    x = Conv2D(filters=ndf*nf_mult, kernel_size=(4,4), strides=1, padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    x = Conv2D(filters=1, kernel_size=(4,4), strides=1, padding='same')(x)\n",
    "    if use_sigmoid:\n",
    "        x = Activation('sigmoid')(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='tanh')(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=x, name='Discriminator')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "\n",
    "def generator_containing_discriminator_multiple_outputs(generator, discriminator):\n",
    "    inputs = Input(shape=image_shape)\n",
    "    generated_images = generator(inputs)\n",
    "    outputs = discriminator(generated_images)\n",
    "    model = Model(inputs=inputs, outputs=[generated_images, outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "image_shape = (256, 256, 3)\n",
    "\n",
    "def perceptual_loss(y_true, y_pred):\n",
    "    vgg = VGG16(include_top=False, weights='imagenet', input_shape=image_shape)\n",
    "    loss_model = Model(inputs=vgg.input, outputs=vgg.get_layer('block3_conv3').output)\n",
    "    loss_model.trainable = False\n",
    "    return K.mean(K.square(loss_model(y_true) - loss_model(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def wasserstein_loss(y_true, y_pred):\n",
    "    return K.mean(y_true*y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/PRNU/data/imgs\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/PRNU/data/imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import math\n",
    "import rwt\n",
    "from scipy import special\n",
    "import csv\n",
    "from random import *\n",
    "import requests\n",
    "import shutil\n",
    "import sqlite3\n",
    "import os\n",
    "import imutils\n",
    "import io\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adapt_array(arr):\n",
    "    # SQL util function - convert np array to sql array\n",
    "    out = io.BytesIO()\n",
    "    np.save(out, arr)\n",
    "    out.seek(0)\n",
    "    return sqlite3.Binary(out.read())\n",
    "\n",
    "def convert_array(text):\n",
    "    # SQL util function - convert sql array to np array\n",
    "    out = io.BytesIO(text)\n",
    "    out.seek(0)\n",
    "    return np.load(out)\n",
    "\n",
    "def getNumber(s):\n",
    "    no = ''\n",
    "    i = -1\n",
    "    while str.isdigit(s[i]):\n",
    "        no += s[i]\n",
    "        i -= 1\n",
    "    no = no[::-1]\n",
    "    return int(no)\n",
    "\n",
    "def getKeys():\n",
    "    # returns all user ids in the DB\n",
    "    cur.execute('SELECT id FROM users')\n",
    "    table_keys_t = cur.fetchall()\n",
    "    table_keys = [i for i in range(len(table_keys_t))]\n",
    "    for i in range(len(table_keys_t)):\n",
    "        table_keys[i] = table_keys_t[i][0]\n",
    "    del table_keys_t\n",
    "    return table_keys\n",
    "\n",
    "def mean2(x):\n",
    "    y = np.sum(x) / np.size(x);\n",
    "    return y\n",
    "\n",
    "def corr2(a,b):\n",
    "    a = a - mean2(a)\n",
    "    b = b - mean2(b)\n",
    "\n",
    "    r = (a*b).sum() / math.sqrt((a*a).sum() * (b*b).sum());\n",
    "    return r\n",
    "\n",
    "def threshold(y,t):\n",
    "    res = y-t\n",
    "    return (res+abs(res))/2\n",
    "\n",
    "def removeNeighborhood(X,x,ssize):\n",
    "    M,N = X.shape[0],X.shape[1]\n",
    "    radius = int((ssize-1)/2)\n",
    "    X = np.roll(X,radius-x[1]+1,axis=1)\n",
    "    X = np.roll(X,radius-x[0]+1,axis=0)\n",
    "    Y = X[ssize:,:ssize]\n",
    "    Y = Y.flatten()\n",
    "    Y = np.append(Y,X[M*ssize:].T)\n",
    "    return Y\n",
    "\n",
    "def qFunction(x):\n",
    "    if(x<37.5):\n",
    "        Q = 1/2*special.erfc(x/math.sqrt(2))\n",
    "        logQ = math.log(Q)\n",
    "    else:\n",
    "        Q = (1/math.sqrt(2*math.pi))/np.multiply(x,np.exp(-np.divide(np.square(x),2)))\n",
    "        logQ = -np.square(x)/2 - np.log(x) - 1/2*math.log(2*math.pi)\n",
    "    return Q,logQ\n",
    "\n",
    "def FAFromPCE(pce,search_space):\n",
    "    p,logP = qFunction(np.sign(pce)*np.sqrt(np.abs(pce)))\n",
    "    if(pce<50):\n",
    "        FA = np.power(1-(1-p),search_space)\n",
    "    else:\n",
    "        FA = search_space * p\n",
    "    if(FA==0):\n",
    "        FA = search_space*p\n",
    "        log10FA = np.log10(search_space) + logP*math.log10(2)\n",
    "    else:\n",
    "        log10FA = np.log10(FA)\n",
    "    return FA,log10FA\n",
    "\n",
    "def zeroMean(X):\n",
    "    reshaped = 0\n",
    "    if(len(X.shape)==2):\n",
    "        X = np.reshape(X,[X.shape[0],X.shape[1],1])\n",
    "        reshaped = 1\n",
    "    M,N,K = X.shape[0],X.shape[1],X.shape[2]\n",
    "    Y = np.zeros(X.shape)\n",
    "    row = np.zeros([M,K])\n",
    "    col = np.zeros([K,N])\n",
    "    for i in range(K):\n",
    "        t = np.mean(X[:,:,i])\n",
    "        X[:,:,i] = X[:,:,i] - t\n",
    "    for i in range(K):\n",
    "        col[i,:] = np.mean(X[:,:,i],axis=0)\n",
    "        row[:,i] = np.mean(X[:,:,i].T,axis=0).T\n",
    "    for j in range(K):\n",
    "        Y[:,:,j]=X[:,:,j]-np.ones([M,1])*col[j,:]\n",
    "    for j in range(K):\n",
    "        t = row[:,j]\n",
    "        t.shape = [t.shape[0],1]\n",
    "        Y[:,:,j]=Y[:,:,j]-t*np.ones([1,N])\n",
    "    if reshaped is 1:\n",
    "        Y = np.reshape(Y,[Y.shape[0],Y.shape[1]])\n",
    "    return Y\n",
    "\n",
    "def zeroMeanTotal(X):\n",
    "    if len(X.shape) != 2:\n",
    "        Y = np.zeros(X.shape)\n",
    "        Z = zeroMean(X[::2,::2,:])\n",
    "        Y[::2,::2,:] = Z\n",
    "        Z = zeroMean(X[::2,1::2,:])\n",
    "        Y[::2,1::2,:] = Z\n",
    "        Z = zeroMean(X[1::2,::2,:])\n",
    "        Y[1::2,::2,:] = Z\n",
    "        Z = zeroMean(X[1::2,1::2,:])\n",
    "        Y[1::2,1::2,:] = Z\n",
    "    else:\n",
    "        Y = np.zeros(X.shape)\n",
    "        Z = zeroMean(X[::2,::2])\n",
    "        Y[::2,::2] = Z\n",
    "        Z = zeroMean(X[::2,1::2])\n",
    "        Y[::2,1::2] = Z\n",
    "        Z = zeroMean(X[1::2,::2])\n",
    "        Y[1::2,::2] = Z\n",
    "        Z = zeroMean(X[1::2,1::2])\n",
    "        Y[1::2,1::2] = Z\n",
    "    return Y\n",
    "\n",
    "def waveNoise(coef,noiseVar):\n",
    "    t = np.square(coef)\n",
    "    filter = np.ones([3,3])/9\n",
    "    coefVar = threshold(cv2.filter2D(t,-1,filter,borderType=cv2.BORDER_CONSTANT),noiseVar)\n",
    "    for w in range(5,10,2):\n",
    "        filter = np.ones([w,w])/(w*w)\n",
    "        EstVar = threshold(cv2.filter2D(t,-1,filter,borderType=cv2.BORDER_CONSTANT),noiseVar)\n",
    "        coefVar = np.minimum(coefVar, EstVar)\n",
    "    return np.divide(np.multiply(coef,noiseVar),np.add(coefVar,noiseVar))\n",
    "\n",
    "def noiseExtract(img,qmf,sigma,L):\n",
    "    M,N = img.shape[0],img.shape[1]\n",
    "    m = 2**L\n",
    "    minpad = 2\n",
    "    nr = math.ceil((M+minpad)/m)*m\n",
    "    nc = math.ceil((N+minpad)/m)*m\n",
    "    pr = math.ceil((nr-M)/2)\n",
    "    prd= math.floor((nr-M)/2)\n",
    "    pc = math.ceil((nc-N)/2)\n",
    "    pcr= math.floor((nc-N)/2)\n",
    "    t1 = np.insert(np.insert(img[pr-1::-1,pc-1::-1],pc,img[pr-1::-1,:].T,axis=1),N+pc,img[pr-1::-1,N-1:N-pcr-1:-1].T,axis=1)\n",
    "    t2 = np.insert(np.insert(img[:,pc-1::-1],pc,img.T,axis=1),N+pc,img[:,N-1:N-pcr-1:-1].T,axis=1)\n",
    "    t3 = np.insert(np.insert(img[M-1:M-prd-1:-1,pc-1::-1],pc,img[M-1:M-prd-1:-1,:].T,axis=1),N+pc,img[M-1:M-prd-1:-1,N-1:N-pcr-1:-1].T,axis=1)\n",
    "    img = np.insert(np.insert(t2,[pr-1],t1,axis=0),pr-1+M,t3,axis=0)\n",
    "    # img = np.float32([[img[pr:1:-1,pc:1:-1],img[pr:1:-1,:],img[pr:1:-1,N:N-pcr+1:-1]],[img[:,pc:1:-1],img,img[:,N:N-pcr+1:-1]],[img[M:M-prd+1:-1,pc:1:-1],img[M:M-prd+1:-1,:],img[M:M-prd+1:-1,N:N-pcr+1:-1]]])    \n",
    "    img = np.float64(img)\n",
    "    NoiseVar = sigma**2\n",
    "    wave_trans = np.zeros([nr,nc])\n",
    "    # print(img.shape)\n",
    "    # cA,(cH,cV,cD) = pywt.dwt2(img,'db4','per')\n",
    "    # wave_trans = np.append(np.append(cA,cH,0),np.append(cV,cD,0),1)\n",
    "    wave_trans = rwt.dwt(img,qmf,L)[0]\n",
    "    for i in range(L):\n",
    "        # Hhigh = [k for k in range(int(nc/2)+1,nc+1)]\n",
    "        # Hlow = [k for k in range(1,int(nc/2)+1)]\n",
    "        # Vhigh = [k for k in range(int(nr/2)+1,nr+1)]\n",
    "        # Vlow = [k for k in range(1,int(nr/2)+1)]\n",
    "        wave_trans[0:int(nr/2),int(nc/2):nc] = np.around(waveNoise(wave_trans[0:int(nr/2),int(nc/2):nc],NoiseVar),4)\n",
    "        wave_trans[int(nr/2):nr,0:int(nc/2)] =  np.around(waveNoise(wave_trans[int(nr/2):nr,0:int(nc/2)],NoiseVar),4)\n",
    "        wave_trans[int(nr/2):nr,int(nc/2):nc] = np.around(waveNoise(wave_trans[int(nr/2):nr,int(nc/2):nc],NoiseVar),4)\n",
    "        nc = int(nc/2)\n",
    "        nr = int(nr/2)\n",
    "    wave_trans[:nr,:nc] = 0\n",
    "    # cA = wave_trans[:136,:136]\n",
    "    # cV = wave_trans[:136,136:]\n",
    "    # cH = wave_trans[136:,:136]\n",
    "    # cD = wave_trans[136:,136:]\n",
    "    # image_noise = pywt.idwt2((cA,(cH,cV,cD)),'db4','per')\n",
    "    image_noise = np.around(rwt.idwt(wave_trans,qmf,L)[0],4)\n",
    "    return image_noise[pr:pr+M,pc:pc+N]\n",
    "\n",
    "def noiseExtractFromImg(img,sigma):\n",
    "    L = 4\n",
    "    qmf = np.array([0.2304,0.7148,0.6309,-0.0280,-0.1870,0.0308,0.0329,-0.0106],dtype=np.float64)\n",
    "    noise = np.zeros(img.shape)\n",
    "    for j in range(3):\n",
    "        noise[:,:,j] = noiseExtract(img[:,:,j],qmf,sigma,L)\n",
    "    noise = noise.astype(np.float32)\n",
    "    noise = zeroMeanTotal(noise)\n",
    "    return noise\n",
    "\n",
    "def intenScale(c):\n",
    "    T = 252\n",
    "    v = 6\n",
    "    out = np.exp(-1*np.divide(np.square(np.subtract(c,T)),v))\n",
    "    out[c<T] = np.divide(c[c<T],T)\n",
    "    return np.around(out,4)\n",
    "\n",
    "def getSaturMap(X):\n",
    "    X = X.astype(np.uint8)\n",
    "    M,N = X.shape[0],X.shape[1]\n",
    "    if(X.max()<=250):\n",
    "        return np.ones(X.shape)\n",
    "    Xh = X - np.roll(X,1,axis=1)\n",
    "    Xv = X - np.roll(X,1,axis=0)\n",
    "    saturMap = np.bitwise_and(Xh,np.bitwise_and(Xv,np.bitwise_and(np.roll(Xh,-1,axis=1),np.roll(Xv,-1,axis=0))))\n",
    "    if(len(X.shape)==3):\n",
    "        for i in range(3):\n",
    "            maxI[i] = X[:,:,i].max()\n",
    "            if maxI[i] > 250:\n",
    "                saturMap[:,:,j] = np.bitwise_not(np.bitwise_and(np.uint8((X[:,:,i]==maxI[i])*1),np.bitwise_not(saturMap[:,:,i])))\n",
    "    else:\n",
    "        maxX = X.max()\n",
    "        saturMap = np.bitwise_not(np.bitwise_and(np.uint8((X==maxX)*1),np.bitwise_not(saturMap)))\n",
    "\n",
    "    return (saturMap>=255)*1\n",
    "\n",
    "def wienerFilter(noise,sigma):\n",
    "    F = np.fft.fft2(noise)\n",
    "    Fmag = np.abs(np.divide(F,math.sqrt(noise.shape[0]*noise.shape[1])))\n",
    "    noiseVar = sigma**2\n",
    "    Fmag1 = waveNoise(Fmag,noiseVar)\n",
    "    Fmag[np.where(Fmag==0)] = 1\n",
    "    Fmag1[np.where(Fmag==0)] = 0\n",
    "    F = np.multiply(F,np.divide(Fmag1,Fmag))\n",
    "    return np.around(np.real(np.fft.ifft2(F)),4)\n",
    "\n",
    "def getFingerprint(imgs):\n",
    "    sigma = 3\n",
    "    L = 4\n",
    "    qmf = np.array([0.2304,0.7148,0.6309,-0.0280,-0.1870,0.0308,0.0329,-0.0106],dtype=np.float64)\n",
    "    RPsum = np.zeros([imgs.shape[3],imgs.shape[1],imgs.shape[2]])\n",
    "    RP = np.zeros([imgs.shape[3],imgs.shape[1],imgs.shape[2]])\n",
    "    NN = np.zeros([imgs.shape[3],imgs.shape[1],imgs.shape[2]])\n",
    "    for i in imgs:\n",
    "        i = i.astype(np.float32,copy=False)\n",
    "        for j in range(3):\n",
    "            imNoise = noiseExtract(i[:,:,j],qmf,sigma,L)\n",
    "            inten = np.multiply(intenScale(i[:,:,j]),getSaturMap(i[:,:,j]))\n",
    "            RPsum[j] = RPsum[j] + np.multiply(imNoise,inten)\n",
    "            NN[j] = NN[j] + np.square(inten)\n",
    "    \n",
    "    for j in range(3):\n",
    "        RP[j] = np.divide(RPsum[j],NN[j]+1)\n",
    "    RP = cv2.merge(RP)\n",
    "    RP = zeroMeanTotal(RP)\n",
    "    RP = RP.astype(np.float32)\n",
    "    return np.around(RP,4)\n",
    "\n",
    "def getCorr(X,Y):\n",
    "    X = np.subtract(X,np.mean(X))\n",
    "    Y = np.subtract(Y,np.mean(Y))\n",
    "    tiltedY = np.fliplr(Y)\n",
    "    tiltedY = np.flipud(tiltedY)\n",
    "    TA = np.fft.fft2(tiltedY)\n",
    "    FA = np.fft.fft2(X)\n",
    "    FF = np.multiply(TA,FA)\n",
    "    return np.real(np.fft.ifft2(FF))\n",
    "\n",
    "def getPCE(C):\n",
    "    squaresize = 11\n",
    "    shift_range = np.uint8([0,0])\n",
    "    if np.any(shift_range>=C.shape):\n",
    "        shift_range = np.minimum(shift_range,C.shape-1)\n",
    "    cInRange = C[C.shape[0]-shift_range[0]-1:,C.shape[1]-shift_range[1]-1:]\n",
    "    (ypeak,xpeak) = np.unravel_index(np.argmax(cInRange, axis=None), cInRange.shape)\n",
    "    peakHeight = cInRange[ypeak,xpeak]\n",
    "    peakLocation = shift_range+np.uint8([1,1])-np.uint8([ypeak,xpeak])\n",
    "    cWithoutPeak = removeNeighborhood(C,np.uint8([ypeak,xpeak]),squaresize)\n",
    "    correl = C[C.shape[0]-1,C.shape[1]-1]\n",
    "    pceEnergy = np.mean(np.multiply(cWithoutPeak,cWithoutPeak))\n",
    "    PCE = peakHeight**2/pceEnergy*np.sign(peakHeight)\n",
    "    pValue = 1/2*special.erfc(peakHeight/math.sqrt(pceEnergy)/math.sqrt(2))\n",
    "    pFA,log10pFA = FAFromPCE(PCE,(shift_range[0]+1)*(shift_range[1]+1))\n",
    "    return pValue,PCE\n",
    "\n",
    "def getResults(fingerprint1,img):\n",
    "    test_img = img\n",
    "    noisex = noiseExtractFromImg(test_img,2)\n",
    "    noisex = wienerFilter(noisex,np.std(noisex))\n",
    "    fingerprint1 = fingerprint1.astype(np.float32)\n",
    "    # fingerprint2 = fingerprint2.astype(np.float32)\n",
    "    noisex = noisex.astype(np.float32)\n",
    "    img = img.astype(np.float32,copy=False)\n",
    "    Ix = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    C = getCorr(noisex,np.multiply(Ix,fingerprint1))\n",
    "    # C = getCorr(fingerprint2,fingerprint1)\n",
    "    x,y = getPCE(C)\n",
    "    return 1.0-x,y\n",
    "\n",
    "def getFingerprintUtil(imgs):\n",
    "    RP = getFingerprint(imgs)\n",
    "    sigmaRP = np.std(RP)\n",
    "    return wienerFilter(RP,sigmaRP)\n",
    "    # if j<=1:\n",
    "    #     RP = getFingerprint(imgs[:1,...])\n",
    "    #     sigmaRP = np.std(RP)\n",
    "    #     return wienerFilter(RP,sigmaRP)\n",
    "    # elif j<=3:\n",
    "    #     RP = getFingerprint(imgs[:2,...])\n",
    "    #     sigmaRP = np.std(RP)\n",
    "    #     return wienerFilter(RP,sigmaRP)\n",
    "    # else:\n",
    "    #     RP = getFingerprint(imgs[:3,...])\n",
    "    #     sigmaRP = np.std(RP)\n",
    "    #     return wienerFilter(RP,sigmaRP)\n",
    "\n",
    "def checkDB(idc,img,sensor_res):\n",
    "    keys = getKeys()\n",
    "    print(keys)\n",
    "    for i in range(len(keys)):\n",
    "        cur.execute('SELECT fingerprint,width,height,pce1,pce2 from users where id=?',(keys[i],))\n",
    "        tt = cur.fetchone()\n",
    "        fp = tt[0]\n",
    "        width = tt[1]\n",
    "        height = tt[2]\n",
    "        pce_val1 = tt[3]\n",
    "        pce_val2 = tt[4]\n",
    "        # print(img.shape)\n",
    "        # print(str(width)+' , '+str(height))\n",
    "        if(sensor_res[0]!=width or sensor_res[1]!=height):\n",
    "            continue\n",
    "        fp = fp.astype(np.float32)\n",
    "        pce = getKorus(fp,img[0])\n",
    "        pce2 = getKorus(fp,img[1])\n",
    "        print('Attacker: '+str(idc)+' Defender: '+str(keys[i])+' PCE1: '+str(pce)+' PCE2: '+str(pce2)+' Req. PCE1: '+str(pce_val1)+' PCE2: '+str(pce_val2))\n",
    "        max_val = 0\n",
    "        if pce_val2<0.002 and pce_val2>0.001 and pce<0.002 and pce>0.001 and pce2<0.002 and pce2>0.001:\n",
    "            print('<<<Duplicate - '+str(idc)+' and '+str(keys[i])+'>>>')\n",
    "            writer.writerows([[idc,keys[i]]])\n",
    "            continue\n",
    "        if pce_val1<0.002 or pce_val2<0.002 or pce<0.002 or pce2<0.002:\n",
    "            continue\n",
    "        # if pce_val1>pce_val2:\n",
    "        #     max_val = pce_val1\n",
    "        #     min_val = pce_val2\n",
    "        # else:\n",
    "        #     max_val = pce_val2\n",
    "        #     min_val = pce_val1\n",
    "        max_val = pce_val2\n",
    "        max_val = round(max_val,4)\n",
    "        a = str(max_val)\n",
    "        ind = a.rfind('0')\n",
    "        if ind<=3:\n",
    "            t = '0.0000'\n",
    "            t = float(t[:ind+1]+'1')\n",
    "            if pce>max_val-t and pce<max_val+t and pce2>max_val-t and pce2<max_val+t:\n",
    "                print('<<<Duplicate - '+str(idc)+' and '+str(keys[i])+'>>>')\n",
    "                writer.writerows([[idc,keys[i]]])\n",
    "\n",
    "def getNearestNeighbour(idc,keys):\n",
    "    max = 0.0\n",
    "    cur.execute('SELECT fingerprint from users where id=?',(idc,))\n",
    "    fingerPrint1 = cur.fetchone()[0]\n",
    "    key = '0'\n",
    "    for i in range(len(keys)):\n",
    "        if keys[i]==idc:\n",
    "            continue\n",
    "        cur.execute('SELECT fingerprint from users where id=?',(keys[i],))\n",
    "        fingerPrint2 = cur.fetchone()[0]\n",
    "        fingerPrint1 = fingerPrint1.astype(np.float32)\n",
    "        fingerPrint2 = fingerPrint2.astype(np.float32)\n",
    "        C = getCorr(fingerPrint1,fingerPrint2)\n",
    "        x,_ = getPCE(C)\n",
    "        if x>max:\n",
    "            max = x\n",
    "            key = keys[i]\n",
    "    return key\n",
    "\n",
    "def highestPCE(fingerprint,imgs,ino,j):\n",
    "    pceValues = np.zeros(j)\n",
    "    for k in range(j):\n",
    "        if k in ino:\n",
    "            continue\n",
    "        xt,pceCorr = getResults(fingerPrint,imgs[k])\n",
    "        pceValues[k] = pceCorr\n",
    "        if xt<0.85:\n",
    "            verd = 'Rejected'\n",
    "        else:\n",
    "            verd = 'Accepted'\n",
    "        # print('Image '+str(k)+' = '+str(pceCorr))\n",
    "        #writer.writerows([[prevID,docsList[k],yt,xt,verd]])\n",
    "    t = np.argmax(pceValues)\n",
    "    if(pceValues[t]<=1):\n",
    "        return fingerprint,ino\n",
    "    ino.append(t)\n",
    "    cluster_imgs = imgs[ino]\n",
    "    return getFingerprintUtil(cluster_imgs),ino\n",
    "\n",
    "def getKorus(fp,img):\n",
    "    img = np.uint8(img)\n",
    "    img_noise = noiseExtractFromImg(img,3)\n",
    "    fp = fp * img\n",
    "    fp = fp - np.mean(fp)\n",
    "    img_noise = img_noise - np.mean(img_noise)\n",
    "    n1 = np.sqrt(np.sum(img_noise*img_noise))\n",
    "    n2 = np.sqrt(np.sum(fp*fp))\n",
    "    return np.sum(img_noise*fp)/(n1*n2)\n",
    "\n",
    "def getKorusFromPrnu(fp1,fp2):\n",
    "    fp = fp1.copy()\n",
    "    tt = fp2.copy()\n",
    "    fp = fp * fp2\n",
    "    fp = fp - np.mean(fp)\n",
    "    tt = tt - np.mean(tt)\n",
    "    n1 = np.sqrt(np.sum(tt*tt))\n",
    "    n2 = np.sqrt(np.sum(fp*fp))\n",
    "    return np.sum(tt*fp)/(n1*n2)\n",
    "\n",
    "def getInitH(imgs):\n",
    "    n = imgs.shape[0]\n",
    "    fingerPrints = np.zeros(imgs.shape[:3])\n",
    "    corrMat = np.zeros([n,n])\n",
    "    for i in range(n):\n",
    "        fingerPrints[i] = getFingerprintUtil(np.float32([imgs[i]]))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i is j:\n",
    "                corrMat[i][j] = 0.0\n",
    "                continue\n",
    "            corrMat[i][j] = corr2(fingerPrints[i],fingerPrints[j])\n",
    "    return corrMat\n",
    "\n",
    "def getProjection(arr,random_arr):\n",
    "    #proj = np.matmul(arr,random_arr)\n",
    "    proj = arr\n",
    "    proj = (proj>=0)*1\n",
    "    proj = np.uint8(proj.flatten())\n",
    "    return proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(370, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# img_list = os.listdir('.')\n",
    "# t = cv2.imread(img_list[0])\n",
    "# t = (t-128)/128\n",
    "# imgs = np.array([t])\n",
    "# for i in img_list:\n",
    "#     t = cv2.imread(i)\n",
    "#     if t.shape[0]==imgs.shape[2] or t.shape[0]==imgs.shape[1]:\n",
    "#         pass\n",
    "#     else:\n",
    "#         continue\n",
    "#     if t.shape[0]==imgs.shape[2]:\n",
    "#         t = imutils.rotate_bound(t,90)\n",
    "#     t = (t-128)/128\n",
    "#     imgs = np.append(imgs,[t],axis=0)\n",
    "# print(imgs.shape)\n",
    "\n",
    "img_list = os.listdir('.')\n",
    "t = cv2.imread(img_list[0])\n",
    "imgs = np.array([getFingerprintUtil(np.array([t]))])\n",
    "for i in img_list:\n",
    "    t = cv2.imread(i)\n",
    "    if t.shape[0]==imgs.shape[2] or t.shape[0]==imgs.shape[1]:\n",
    "        pass\n",
    "    else:\n",
    "        continue\n",
    "    if t.shape[0]==imgs.shape[2]:\n",
    "        t = imutils.rotate_bound(t,90)\n",
    "    t = getFingerprintUtil(np.array([t]))\n",
    "    imgs = np.append(imgs,[t],axis=0)\n",
    "print(imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/PRNU/data/prnu\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/PRNU/data/prnu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(280, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "prnu_list = os.listdir('.')\n",
    "prnus = np.array([np.load(prnu_list[0])])\n",
    "for i in prnu_list[1:]:\n",
    "    t = np.load(i)\n",
    "    prnus = np.append(prnus,[t],axis=0)\n",
    "print(prnus.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/PRNU/data\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/PRNU/data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "\n",
    "g = generator_model()\n",
    "d = discriminator_model()\n",
    "d_on_g = generator_containing_discriminator_multiple_outputs(g, d)\n",
    "\n",
    "g_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "d_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "d_on_g_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "d.trainable = True\n",
    "d.compile(optimizer=d_opt, loss=wasserstein_loss)\n",
    "d.trainable = False\n",
    "loss = [perceptual_loss, wasserstein_loss]\n",
    "loss_weights = [100, 1]\n",
    "d_on_g.compile(optimizer=d_on_g_opt, loss=loss, loss_weights=loss_weights)\n",
    "d.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_all_weights(d, g, epoch_number, current_loss):\n",
    "    now = datetime.datetime.now()\n",
    "    save_dir = os.path.join(BASE_DIR, '{}{}'.format(now.month, now.day))\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    g.save_weights(os.path.join(save_dir, 'generator_{}_{}.h5'.format(epoch_number, current_loss)), True)\n",
    "    d.save_weights(os.path.join(save_dir, 'discriminator_{}.h5'.format(epoch_number)), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 0.056820625916589054\n",
      "batch 1 d_on_g_loss : [4326.8281, 43.264885, 0.33999485]\n",
      "batch 2 d_loss : 0.04443447075318545\n",
      "batch 2 d_on_g_loss : [4345.5825, 43.454971, 0.085366644]\n",
      "batch 3 d_loss : 0.03371583658202629\n",
      "batch 3 d_on_g_loss : [4195.7012, 41.956921, 0.0093528125]\n",
      "batch 4 d_loss : 0.02550871691237262\n",
      "batch 4 d_on_g_loss : [4659.2319, 46.592308, 0.0010895543]\n",
      "batch 5 d_loss : 0.020466888699156697\n",
      "batch 5 d_on_g_loss : [4653.4707, 46.534702, 0.0003546433]\n",
      "batch 6 d_loss : 0.017083890238670088\n",
      "batch 6 d_on_g_loss : [3572.7346, 35.727345, 0.00024797532]\n",
      "batch 7 d_loss : 0.014663070048637955\n",
      "batch 7 d_on_g_loss : [4171.8755, 41.71875, 0.00025255434]\n",
      "batch 8 d_loss : 0.012841863626090345\n",
      "batch 8 d_on_g_loss : [3723.8533, 37.238529, 0.00023604796]\n",
      "batch 9 d_loss : 0.011424010745637739\n",
      "batch 9 d_on_g_loss : [4176.085, 41.760845, 0.00025784786]\n",
      "batch 10 d_loss : 0.010286838801403065\n",
      "batch 10 d_on_g_loss : [3791.8276, 37.918274, 0.00014705356]\n",
      "batch 11 d_loss : 0.009356049059583298\n",
      "batch 11 d_on_g_loss : [4241.2158, 42.412159, 0.00011431998]\n",
      "batch 12 d_loss : 0.008582787901104894\n",
      "batch 12 d_on_g_loss : [3915.4119, 39.154118, 8.3278406e-05]\n",
      "batch 13 d_loss : 0.007927234160664598\n",
      "batch 13 d_on_g_loss : [3628.8992, 36.28899, 0.00015854]\n",
      "batch 14 d_loss : 0.007365360747748387\n",
      "batch 14 d_on_g_loss : [4090.874, 40.908737, 0.00012888803]\n",
      "batch 15 d_loss : 0.00687795179032643\n",
      "batch 15 d_on_g_loss : [3908.4214, 39.084213, 9.5291238e-05]\n",
      "batch 16 d_loss : 0.006451046384836445\n",
      "batch 16 d_on_g_loss : [4029.606, 40.296059, 0.00010655707]\n",
      "batch 17 d_loss : 0.006073370255527313\n",
      "batch 17 d_on_g_loss : [3428.3242, 34.283241, 6.4125183e-05]\n",
      "batch 18 d_loss : 0.00573782914339568\n",
      "batch 18 d_on_g_loss : [3889.6743, 38.896744, 7.8718185e-05]\n",
      "batch 19 d_loss : 0.005437548879375467\n",
      "batch 19 d_on_g_loss : [3284.3274, 32.843273, 5.0522376e-05]\n",
      "batch 20 d_loss : 0.005167988926750695\n",
      "batch 20 d_on_g_loss : [3518.679, 35.18679, 0.0001095405]\n",
      "batch 21 d_loss : 0.004923194571494518\n",
      "batch 21 d_on_g_loss : [3295.9041, 32.959042, 6.1359933e-05]\n",
      "batch 22 d_loss : 0.004700485724490797\n",
      "batch 22 d_on_g_loss : [3402.6094, 34.026093, 5.1212985e-05]\n",
      "batch 23 d_loss : 0.004497382499539526\n",
      "batch 23 d_on_g_loss : [3905.2681, 39.052681, 5.7609723e-05]\n",
      "batch 24 d_loss : 0.004310994504506501\n",
      "batch 24 d_on_g_loss : [3567.2307, 35.672306, 9.1278125e-05]\n",
      "batch 25 d_loss : 0.004140032123177662\n",
      "batch 25 d_on_g_loss : [3764.4456, 37.644455, 5.1058552e-05]\n",
      "batch 26 d_loss : 0.003981636219717844\n",
      "batch 26 d_on_g_loss : [3505.6531, 35.05653, 4.245757e-05]\n",
      "batch 27 d_loss : 0.003835164744493711\n",
      "batch 27 d_on_g_loss : [3404.8618, 34.048618, 4.4280889e-05]\n",
      "batch 28 d_loss : 0.003698980672379548\n",
      "batch 28 d_on_g_loss : [3426.345, 34.263451, 3.2939766e-05]\n",
      "batch 29 d_loss : 0.003572236984598868\n",
      "batch 29 d_on_g_loss : [3871.6396, 38.716396, 3.9810227e-05]\n",
      "batch 30 d_loss : 0.0034536621309052863\n",
      "batch 30 d_on_g_loss : [3565.5015, 35.655014, 3.052568e-05]\n",
      "batch 31 d_loss : 0.003342698133934802\n",
      "batch 31 d_on_g_loss : [3089.5808, 30.895807, 2.8213455e-05]\n",
      "batch 32 d_loss : 0.00323871000168765\n",
      "batch 32 d_on_g_loss : [3086.6978, 30.866978, 3.2012609e-05]\n",
      "batch 33 d_loss : 0.003141054304918119\n",
      "batch 33 d_on_g_loss : [3315.26, 33.152599, 3.9084851e-05]\n",
      "batch 34 d_loss : 0.0030492681115741587\n",
      "batch 34 d_on_g_loss : [3667.3503, 36.673504, 3.8101753e-05]\n",
      "batch 35 d_loss : 0.002962436688186634\n",
      "batch 35 d_on_g_loss : [4054.6882, 40.546883, 2.7397111e-05]\n",
      "epoch: 1/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 9.596488234819845e-06\n",
      "batch 1 d_on_g_loss : [3128.4341, 31.284342, 3.944038e-05]\n",
      "batch 2 d_loss : 1.0646007740433561e-05\n",
      "batch 2 d_on_g_loss : [3482.2346, 34.822346, 2.9941937e-05]\n",
      "batch 3 d_loss : 1.0732751676793366e-05\n",
      "batch 3 d_on_g_loss : [3221.5615, 32.215614, 2.008686e-05]\n",
      "batch 4 d_loss : 1.038870677803061e-05\n",
      "batch 4 d_on_g_loss : [3415.4744, 34.154743, 4.9183112e-05]\n",
      "batch 5 d_loss : 1.0634813479555305e-05\n",
      "batch 5 d_on_g_loss : [3634.4421, 36.344421, 3.0787091e-05]\n",
      "batch 6 d_loss : 1.001604797844872e-05\n",
      "batch 6 d_on_g_loss : [3420.6787, 34.206787, 2.3493263e-05]\n",
      "batch 7 d_loss : 1.0633886176947271e-05\n",
      "batch 7 d_on_g_loss : [3235.894, 32.35894, 2.7665874e-05]\n",
      "batch 8 d_loss : 1.0075956026867061e-05\n",
      "batch 8 d_on_g_loss : [2855.5281, 28.555281, 1.7222366e-05]\n",
      "batch 9 d_loss : 9.68489155436853e-06\n",
      "batch 9 d_on_g_loss : [3275.3284, 32.753284, 2.5820842e-05]\n",
      "batch 10 d_loss : 9.68609355368244e-06\n",
      "batch 10 d_on_g_loss : [3681.9504, 36.819504, 1.8702533e-05]\n",
      "batch 11 d_loss : 9.67017011300248e-06\n",
      "batch 11 d_on_g_loss : [3612.2947, 36.122948, 2.9299217e-05]\n",
      "batch 12 d_loss : 9.568158679940097e-06\n",
      "batch 12 d_on_g_loss : [3378.1731, 33.781731, 2.5772657e-05]\n",
      "batch 13 d_loss : 9.486546829206277e-06\n",
      "batch 13 d_on_g_loss : [3516.2766, 35.162766, 3.2444856e-05]\n",
      "batch 14 d_loss : 9.336398846114337e-06\n",
      "batch 14 d_on_g_loss : [2892.4814, 28.924814, 1.8897314e-05]\n",
      "batch 15 d_loss : 9.11584532635364e-06\n",
      "batch 15 d_on_g_loss : [3228.7576, 32.287575, 1.3933397e-05]\n",
      "batch 16 d_loss : 9.144984107933852e-06\n",
      "batch 16 d_on_g_loss : [3945.0505, 39.450504, 2.0255204e-05]\n",
      "batch 17 d_loss : 8.989012921494363e-06\n",
      "batch 17 d_on_g_loss : [2989.9524, 29.899523, 2.8675346e-05]\n",
      "batch 18 d_loss : 8.930044365721794e-06\n",
      "batch 18 d_on_g_loss : [3290.7578, 32.907578, 2.3075147e-05]\n",
      "batch 19 d_loss : 8.878619581465549e-06\n",
      "batch 19 d_on_g_loss : [3517.4312, 35.174313, 2.2862801e-05]\n",
      "batch 20 d_loss : 8.763276941863296e-06\n",
      "batch 20 d_on_g_loss : [3078.8826, 30.788826, 2.2848999e-05]\n",
      "batch 21 d_loss : 8.802886913188213e-06\n",
      "batch 21 d_on_g_loss : [3465.6184, 34.656185, 1.4793369e-05]\n",
      "batch 22 d_loss : 8.730539324956639e-06\n",
      "batch 22 d_on_g_loss : [3326.978, 33.269779, 2.0773965e-05]\n",
      "batch 23 d_loss : 8.594021690679137e-06\n",
      "batch 23 d_on_g_loss : [3029.0288, 30.290287, 2.1141535e-05]\n",
      "batch 24 d_loss : 8.45459194730817e-06\n",
      "batch 24 d_on_g_loss : [2919.9932, 29.199932, 1.7709102e-05]\n",
      "batch 25 d_loss : 8.45830374964862e-06\n",
      "batch 25 d_on_g_loss : [3068.3677, 30.683676, 1.4794272e-05]\n",
      "batch 26 d_loss : 8.347406460765902e-06\n",
      "batch 26 d_on_g_loss : [3045.8142, 30.458141, 1.6878623e-05]\n",
      "batch 27 d_loss : 8.242831487829486e-06\n",
      "batch 27 d_on_g_loss : [3500.8638, 35.008636, 1.6477767e-05]\n",
      "batch 28 d_loss : 8.224496238134244e-06\n",
      "batch 28 d_on_g_loss : [2848.2051, 28.482052, 1.3644705e-05]\n",
      "batch 29 d_loss : 8.150378841397971e-06\n",
      "batch 29 d_on_g_loss : [3124.7371, 31.247372, 1.2289128e-05]\n",
      "batch 30 d_loss : 8.083666198217543e-06\n",
      "batch 30 d_on_g_loss : [3185.6516, 31.856516, 1.6365851e-05]\n",
      "batch 31 d_loss : 8.003705490057567e-06\n",
      "batch 31 d_on_g_loss : [3018.1882, 30.181883, 1.3220017e-05]\n",
      "batch 32 d_loss : 7.86476844467643e-06\n",
      "batch 32 d_on_g_loss : [2952.4326, 29.524326, 2.1431673e-05]\n",
      "batch 33 d_loss : 7.782092343129052e-06\n",
      "batch 33 d_on_g_loss : [2977.3115, 29.773115, 1.0444264e-05]\n",
      "batch 34 d_loss : 7.660012023038956e-06\n",
      "batch 34 d_on_g_loss : [2881.2385, 28.812386, 1.2975454e-05]\n",
      "batch 35 d_loss : 7.590099464453358e-06\n",
      "batch 35 d_on_g_loss : [2954.5066, 29.545067, 1.6572736e-05]\n",
      "epoch: 2/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 7.589117467432516e-06\n",
      "batch 1 d_on_g_loss : [3162.1392, 31.621391, 1.1919818e-05]\n",
      "batch 2 d_loss : 5.343141538105556e-06\n",
      "batch 2 d_on_g_loss : [3012.8904, 30.128904, 8.2702836e-06]\n",
      "batch 3 d_loss : 5.824221292035266e-06\n",
      "batch 3 d_on_g_loss : [3035.6294, 30.356295, 1.0602228e-05]\n",
      "batch 4 d_loss : 5.200266036808898e-06\n",
      "batch 4 d_on_g_loss : [2949.9724, 29.499723, 1.2052915e-05]\n",
      "batch 5 d_loss : 5.010609402233967e-06\n",
      "batch 5 d_on_g_loss : [2861.3213, 28.613213, 8.9685436e-06]\n",
      "batch 6 d_loss : 5.15301141300976e-06\n",
      "batch 6 d_on_g_loss : [3069.9053, 30.699053, 1.4123307e-05]\n",
      "batch 7 d_loss : 4.957550169949952e-06\n",
      "batch 7 d_on_g_loss : [3033.5264, 30.335264, 8.7173612e-06]\n",
      "batch 8 d_loss : 4.799737189387087e-06\n",
      "batch 8 d_on_g_loss : [2839.4495, 28.394495, 1.0756976e-05]\n",
      "batch 9 d_loss : 4.55427839875079e-06\n",
      "batch 9 d_on_g_loss : [3190.7917, 31.907917, 1.4833355e-05]\n",
      "batch 10 d_loss : 4.562029325825279e-06\n",
      "batch 10 d_on_g_loss : [3349.5911, 33.495911, 1.2781209e-05]\n",
      "batch 11 d_loss : 4.523374983281511e-06\n",
      "batch 11 d_on_g_loss : [3301.7427, 33.017426, 7.5530788e-06]\n",
      "batch 12 d_loss : 4.520329684964963e-06\n",
      "batch 12 d_on_g_loss : [3749.8618, 37.498619, 8.9596087e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 13 d_loss : 4.381472437951463e-06\n",
      "batch 13 d_on_g_loss : [2868.7756, 28.687757, 8.5678294e-06]\n",
      "batch 14 d_loss : 4.3101171221288884e-06\n",
      "batch 14 d_on_g_loss : [3063.4949, 30.634949, 9.5370624e-06]\n",
      "batch 15 d_loss : 4.280794685958729e-06\n",
      "batch 15 d_on_g_loss : [3109.1353, 31.091352, 2.1156819e-05]\n",
      "batch 16 d_loss : 4.341512180872087e-06\n",
      "batch 16 d_on_g_loss : [3072.4497, 30.724497, 7.8034327e-06]\n",
      "batch 17 d_loss : 4.253151452276677e-06\n",
      "batch 17 d_on_g_loss : [3040.6099, 30.406099, 1.15432e-05]\n",
      "batch 18 d_loss : 4.2279120786285296e-06\n",
      "batch 18 d_on_g_loss : [2951.9702, 29.519703, 9.6877438e-06]\n",
      "batch 19 d_loss : 4.115730433496585e-06\n",
      "batch 19 d_on_g_loss : [2815.2961, 28.152962, 6.7446063e-06]\n",
      "batch 20 d_loss : 4.036749526221684e-06\n",
      "batch 20 d_on_g_loss : [3432.5479, 34.325478, 9.3345243e-06]\n",
      "batch 21 d_loss : 4.005484981375741e-06\n",
      "batch 21 d_on_g_loss : [3249.585, 32.49585, 8.3068262e-06]\n",
      "batch 22 d_loss : 3.9432437502413945e-06\n",
      "batch 22 d_on_g_loss : [3433.5979, 34.335979, 6.9992498e-06]\n",
      "batch 23 d_loss : 3.961483241215793e-06\n",
      "batch 23 d_on_g_loss : [2694.0359, 26.940359, 1.1137708e-05]\n",
      "batch 24 d_loss : 3.9491533319354255e-06\n",
      "batch 24 d_on_g_loss : [3502.2747, 35.022747, 6.083515e-06]\n",
      "batch 25 d_loss : 3.886879554556799e-06\n",
      "batch 25 d_on_g_loss : [2797.5005, 27.975006, 9.466703e-06]\n",
      "batch 26 d_loss : 3.816806866570215e-06\n",
      "batch 26 d_on_g_loss : [2839.231, 28.392309, 8.4834519e-06]\n",
      "batch 27 d_loss : 3.8116472414576157e-06\n",
      "batch 27 d_on_g_loss : [2944.3242, 29.443243, 6.6510702e-06]\n",
      "batch 28 d_loss : 3.7421796508039863e-06\n",
      "batch 28 d_on_g_loss : [3137.0762, 31.370762, 5.9425861e-06]\n",
      "batch 29 d_loss : 3.7141949774352193e-06\n",
      "batch 29 d_on_g_loss : [3076.5632, 30.765633, 7.2004987e-06]\n",
      "batch 30 d_loss : 3.689076687199607e-06\n",
      "batch 30 d_on_g_loss : [3215.2454, 32.152454, 5.8263599e-06]\n",
      "batch 31 d_loss : 3.644466570192655e-06\n",
      "batch 31 d_on_g_loss : [2556.4377, 25.564377, 1.1164035e-05]\n",
      "batch 32 d_loss : 3.5636862257604206e-06\n",
      "batch 32 d_on_g_loss : [2985.3574, 29.853575, 7.1969262e-06]\n",
      "batch 33 d_loss : 3.525511563869562e-06\n",
      "batch 33 d_on_g_loss : [2654.9978, 26.549978, 8.492234e-06]\n",
      "batch 34 d_loss : 3.5042117180155937e-06\n",
      "batch 34 d_on_g_loss : [2685.1899, 26.851898, 7.7064869e-06]\n",
      "batch 35 d_loss : 3.476907688439366e-06\n",
      "batch 35 d_on_g_loss : [2863.2197, 28.632198, 5.2264631e-06]\n",
      "epoch: 3/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 2.8948918952664824e-06\n",
      "batch 1 d_on_g_loss : [3118.0293, 31.180294, 8.0176414e-06]\n",
      "batch 2 d_loss : 2.68400535787805e-06\n",
      "batch 2 d_on_g_loss : [2910.6091, 29.106091, 5.3582426e-06]\n",
      "batch 3 d_loss : 2.536228430471965e-06\n",
      "batch 3 d_on_g_loss : [2691.9158, 26.919157, 6.6048028e-06]\n",
      "batch 4 d_loss : 2.421771716853982e-06\n",
      "batch 4 d_on_g_loss : [2870.3667, 28.703667, 7.3543029e-06]\n",
      "batch 5 d_loss : 2.488803293090314e-06\n",
      "batch 5 d_on_g_loss : [3324.6821, 33.246822, 1.0115416e-05]\n",
      "batch 6 d_loss : 2.3414570364366226e-06\n",
      "batch 6 d_on_g_loss : [2757.73, 27.577299, 6.0713469e-06]\n",
      "batch 7 d_loss : 2.2647661093547608e-06\n",
      "batch 7 d_on_g_loss : [2784.7852, 27.847853, 6.4225605e-06]\n",
      "batch 8 d_loss : 2.1827545026553706e-06\n",
      "batch 8 d_on_g_loss : [3223.1006, 32.231007, 4.2104548e-06]\n",
      "batch 9 d_loss : 2.3499437904522186e-06\n",
      "batch 9 d_on_g_loss : [3025.8926, 30.258926, 4.7883432e-06]\n",
      "batch 10 d_loss : 2.307600793756137e-06\n",
      "batch 10 d_on_g_loss : [2907.8394, 29.078394, 7.1605587e-06]\n",
      "batch 11 d_loss : 2.340025697445857e-06\n",
      "batch 11 d_on_g_loss : [2697.2661, 26.972662, 8.6428527e-06]\n",
      "batch 12 d_loss : 2.2878910992100525e-06\n",
      "batch 12 d_on_g_loss : [3182.9834, 31.829834, 9.8717564e-06]\n",
      "batch 13 d_loss : 2.295918987399021e-06\n",
      "batch 13 d_on_g_loss : [2887.6914, 28.876915, 5.6852314e-06]\n",
      "batch 14 d_loss : 2.2618616542656256e-06\n",
      "batch 14 d_on_g_loss : [2969.9517, 29.699516, 5.8504165e-06]\n",
      "batch 15 d_loss : 2.2948467115687286e-06\n",
      "batch 15 d_on_g_loss : [3068.3328, 30.683329, 4.456871e-06]\n",
      "batch 16 d_loss : 2.2480276911096553e-06\n",
      "batch 16 d_on_g_loss : [3162.3096, 31.623095, 5.5742462e-06]\n",
      "batch 17 d_loss : 2.291646306088403e-06\n",
      "batch 17 d_on_g_loss : [3451.9451, 34.519451, 3.8754233e-06]\n",
      "batch 18 d_loss : 2.256687107799533e-06\n",
      "batch 18 d_on_g_loss : [2947.0198, 29.470198, 5.424331e-06]\n",
      "batch 19 d_loss : 2.2833402561828784e-06\n",
      "batch 19 d_on_g_loss : [2979.9963, 29.799963, 6.6090415e-06]\n",
      "batch 20 d_loss : 2.230882065532569e-06\n",
      "batch 20 d_on_g_loss : [3020.688, 30.206879, 3.6342285e-06]\n",
      "batch 21 d_loss : 2.1927904591783383e-06\n",
      "batch 21 d_on_g_loss : [2996.5515, 29.965515, 4.5214183e-06]\n",
      "batch 22 d_loss : 2.2354635844253194e-06\n",
      "batch 22 d_on_g_loss : [2640.198, 26.401979, 6.0403036e-06]\n",
      "batch 23 d_loss : 2.212264285330805e-06\n",
      "batch 23 d_on_g_loss : [2856.7512, 28.567513, 4.0638902e-06]\n",
      "batch 24 d_loss : 2.195771752629601e-06\n",
      "batch 24 d_on_g_loss : [2864.9985, 28.649984, 3.585156e-06]\n",
      "batch 25 d_loss : 2.1817980968990013e-06\n",
      "batch 25 d_on_g_loss : [2879.8169, 28.79817, 4.1752428e-06]\n",
      "batch 26 d_loss : 2.1504633720654127e-06\n",
      "batch 26 d_on_g_loss : [3275.0156, 32.750156, 4.0391301e-06]\n",
      "batch 27 d_loss : 2.122815859635281e-06\n",
      "batch 27 d_on_g_loss : [2989.4426, 29.894426, 4.1246531e-06]\n",
      "batch 28 d_loss : 2.0879998739279212e-06\n",
      "batch 28 d_on_g_loss : [2827.7407, 28.277407, 4.8587708e-06]\n",
      "batch 29 d_loss : 2.0525135855207515e-06\n",
      "batch 29 d_on_g_loss : [2846.8015, 28.468016, 4.4102917e-06]\n",
      "batch 30 d_loss : 2.0477191765166935e-06\n",
      "batch 30 d_on_g_loss : [2810.2544, 28.102545, 6.5002878e-06]\n",
      "batch 31 d_loss : 2.0594809411118e-06\n",
      "batch 31 d_on_g_loss : [2466.4888, 24.664888, 4.7226645e-06]\n",
      "batch 32 d_loss : 2.0709953048481113e-06\n",
      "batch 32 d_on_g_loss : [3112.4011, 31.124012, 3.4224076e-06]\n",
      "batch 33 d_loss : 2.075398129598012e-06\n",
      "batch 33 d_on_g_loss : [2925.4141, 29.254141, 4.5297024e-06]\n",
      "batch 34 d_loss : 2.0577547662897438e-06\n",
      "batch 34 d_on_g_loss : [3100.6606, 31.006607, 3.2431485e-06]\n",
      "batch 35 d_loss : 2.0247843339607894e-06\n",
      "batch 35 d_on_g_loss : [3170.7661, 31.707661, 4.0705168e-06]\n",
      "epoch: 4/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 1.3214913224146585e-06\n",
      "batch 1 d_on_g_loss : [3101.5762, 31.015762, 4.2123665e-06]\n",
      "batch 2 d_loss : 1.5007524780230597e-06\n",
      "batch 2 d_on_g_loss : [3042.7112, 30.427111, 3.7227001e-06]\n",
      "batch 3 d_loss : 1.552565443792749e-06\n",
      "batch 3 d_on_g_loss : [3032.2261, 30.32226, 4.342146e-06]\n",
      "batch 4 d_loss : 1.4299501287950988e-06\n",
      "batch 4 d_on_g_loss : [2956.426, 29.56426, 3.1169104e-06]\n",
      "batch 5 d_loss : 1.5322737317546852e-06\n",
      "batch 5 d_on_g_loss : [2609.2551, 26.09255, 2.6989733e-06]\n",
      "batch 6 d_loss : 1.5238370451697847e-06\n",
      "batch 6 d_on_g_loss : [2707.2976, 27.072975, 4.8882057e-06]\n",
      "batch 7 d_loss : 1.4028293516535736e-06\n",
      "batch 7 d_on_g_loss : [2698.8574, 26.988575, 6.2267754e-06]\n",
      "batch 8 d_loss : 1.4063526450058816e-06\n",
      "batch 8 d_on_g_loss : [2765.7092, 27.657093, 3.9627284e-06]\n",
      "batch 9 d_loss : 1.385622639797172e-06\n",
      "batch 9 d_on_g_loss : [2951.7878, 29.517878, 4.5879251e-06]\n",
      "batch 10 d_loss : 1.365210044923515e-06\n",
      "batch 10 d_on_g_loss : [3109.1233, 31.091232, 3.970958e-06]\n",
      "batch 11 d_loss : 1.4017124333969895e-06\n",
      "batch 11 d_on_g_loss : [3190.9297, 31.909298, 5.3564881e-06]\n",
      "batch 12 d_loss : 1.366759479992652e-06\n",
      "batch 12 d_on_g_loss : [3396.9783, 33.969784, 3.1885859e-06]\n",
      "batch 13 d_loss : 1.37573248366607e-06\n",
      "batch 13 d_on_g_loss : [2671.0854, 26.710855, 4.0745408e-06]\n",
      "batch 14 d_loss : 1.3817528002034253e-06\n",
      "batch 14 d_on_g_loss : [3094.8994, 30.948994, 4.1637895e-06]\n",
      "batch 15 d_loss : 1.3567689279625482e-06\n",
      "batch 15 d_on_g_loss : [2502.4753, 25.024754, 2.6914277e-06]\n",
      "batch 16 d_loss : 1.335382469136448e-06\n",
      "batch 16 d_on_g_loss : [2564.5579, 25.645578, 2.9091877e-06]\n",
      "batch 17 d_loss : 1.3424182156995812e-06\n",
      "batch 17 d_on_g_loss : [2679.696, 26.796961, 8.0660138e-06]\n",
      "batch 18 d_loss : 1.3669513167416072e-06\n",
      "batch 18 d_on_g_loss : [3329.5276, 33.295277, 4.1904641e-06]\n",
      "batch 19 d_loss : 1.3873715482460332e-06\n",
      "batch 19 d_on_g_loss : [3033.355, 30.333549, 2.6874075e-06]\n",
      "batch 20 d_loss : 1.373725315829688e-06\n",
      "batch 20 d_on_g_loss : [2781.2781, 27.81278, 4.7839294e-06]\n",
      "batch 21 d_loss : 1.3565599823821338e-06\n",
      "batch 21 d_on_g_loss : [3003.7546, 30.037546, 3.3755337e-06]\n",
      "batch 22 d_loss : 1.3602210654798084e-06\n",
      "batch 22 d_on_g_loss : [2764.6633, 27.646633, 4.2788997e-06]\n",
      "batch 23 d_loss : 1.3410766255021925e-06\n",
      "batch 23 d_on_g_loss : [2854.7158, 28.547157, 3.2177716e-06]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 24 d_loss : 1.3416776918499333e-06\n",
      "batch 24 d_on_g_loss : [2768.0981, 27.680981, 2.7704455e-06]\n",
      "batch 25 d_loss : 1.3378949888647185e-06\n",
      "batch 25 d_on_g_loss : [2875.5847, 28.755848, 3.7821424e-06]\n",
      "batch 26 d_loss : 1.3200096807745117e-06\n",
      "batch 26 d_on_g_loss : [2971.7922, 29.717922, 3.3166834e-06]\n",
      "batch 27 d_loss : 1.3155814355269723e-06\n",
      "batch 27 d_on_g_loss : [3005.7949, 30.057949, 2.192231e-06]\n",
      "batch 28 d_loss : 1.3133668626811154e-06\n",
      "batch 28 d_on_g_loss : [2896.3669, 28.963669, 2.7965e-06]\n",
      "batch 29 d_loss : 1.339852336702185e-06\n",
      "batch 29 d_on_g_loss : [2762.3943, 27.623943, 3.639605e-06]\n",
      "batch 30 d_loss : 1.3421199760917564e-06\n",
      "batch 30 d_on_g_loss : [2712.3782, 27.123781, 1.8530743e-06]\n",
      "batch 31 d_loss : 1.3291483480403962e-06\n",
      "batch 31 d_on_g_loss : [3107.9724, 31.079725, 4.2818292e-06]\n",
      "batch 32 d_loss : 1.3118900088926466e-06\n",
      "batch 32 d_on_g_loss : [2771.7603, 27.717602, 2.1626131e-06]\n",
      "batch 33 d_loss : 1.3058112889060188e-06\n",
      "batch 33 d_on_g_loss : [2744.2188, 27.442188, 4.8845309e-06]\n",
      "batch 34 d_loss : 1.2926426563808492e-06\n",
      "batch 34 d_on_g_loss : [2606.0471, 26.060471, 2.2672127e-06]\n",
      "batch 35 d_loss : 1.2945648225987887e-06\n",
      "batch 35 d_on_g_loss : [2822.5881, 28.225882, 2.3570071e-06]\n",
      "epoch: 5/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 1.0521135436647455e-06\n",
      "batch 1 d_on_g_loss : [2880.0642, 28.800642, 3.5486551e-06]\n",
      "batch 2 d_loss : 1.3490964079210244e-06\n",
      "batch 2 d_on_g_loss : [3458.8948, 34.588947, 3.3451643e-06]\n",
      "batch 3 d_loss : 1.3205075674704859e-06\n",
      "batch 3 d_on_g_loss : [2842.1011, 28.421011, 3.0568772e-06]\n",
      "batch 4 d_loss : 1.2576365861605155e-06\n",
      "batch 4 d_on_g_loss : [3005.155, 30.05155, 4.0145005e-06]\n",
      "batch 5 d_loss : 1.2004762538708747e-06\n",
      "batch 5 d_on_g_loss : [2766.6875, 27.666876, 1.9446304e-06]\n",
      "batch 6 d_loss : 1.1351880914389768e-06\n",
      "batch 6 d_on_g_loss : [2445.7102, 24.457102, 2.8679324e-06]\n",
      "batch 7 d_loss : 1.0813447894569045e-06\n",
      "batch 7 d_on_g_loss : [2883.502, 28.83502, 2.4827109e-06]\n",
      "batch 8 d_loss : 1.0262043829811774e-06\n",
      "batch 8 d_on_g_loss : [2664.9631, 26.649632, 3.3949725e-06]\n",
      "batch 9 d_loss : 1.0961761000140136e-06\n",
      "batch 9 d_on_g_loss : [3430.4658, 34.304657, 2.8377185e-06]\n",
      "batch 10 d_loss : 1.098598867201872e-06\n",
      "batch 10 d_on_g_loss : [2495.5952, 24.955952, 1.9449885e-06]\n",
      "batch 11 d_loss : 1.0669785607123313e-06\n",
      "batch 11 d_on_g_loss : [2707.8391, 27.078392, 1.8306795e-06]\n",
      "batch 12 d_loss : 1.0423081486502876e-06\n",
      "batch 12 d_on_g_loss : [2491.9136, 24.919136, 2.3931957e-06]\n",
      "batch 13 d_loss : 1.025749792496264e-06\n",
      "batch 13 d_on_g_loss : [2856.6985, 28.566984, 1.6095744e-06]\n",
      "batch 14 d_loss : 1.0154202016110504e-06\n",
      "batch 14 d_on_g_loss : [2418.9224, 24.189224, 2.4407548e-06]\n",
      "batch 15 d_loss : 9.95143985467924e-07\n",
      "batch 15 d_on_g_loss : [2715.8057, 27.158056, 2.1437804e-06]\n",
      "batch 16 d_loss : 9.919382200962445e-07\n",
      "batch 16 d_on_g_loss : [2878.6443, 28.786444, 2.3152315e-06]\n",
      "batch 17 d_loss : 9.783985587198593e-07\n",
      "batch 17 d_on_g_loss : [2975.1545, 29.751545, 2.1551589e-06]\n",
      "batch 18 d_loss : 9.732271709910694e-07\n",
      "batch 18 d_on_g_loss : [2614.9619, 26.149618, 2.2750537e-06]\n",
      "batch 19 d_loss : 9.511195272400648e-07\n",
      "batch 19 d_on_g_loss : [2974.4443, 29.744444, 3.4305147e-06]\n",
      "batch 20 d_loss : 9.372487409109454e-07\n",
      "batch 20 d_on_g_loss : [3035.1548, 30.351547, 1.9677775e-06]\n",
      "batch 21 d_loss : 9.39935199269149e-07\n",
      "batch 21 d_on_g_loss : [2875.8608, 28.758608, 2.4257815e-06]\n",
      "batch 22 d_loss : 9.3114908074974e-07\n",
      "batch 22 d_on_g_loss : [2819.3943, 28.193943, 1.9136876e-06]\n",
      "batch 23 d_loss : 9.368566417794247e-07\n",
      "batch 23 d_on_g_loss : [3037.3025, 30.373026, 2.4808885e-06]\n",
      "batch 24 d_loss : 9.306890978185341e-07\n",
      "batch 24 d_on_g_loss : [2848.2905, 28.482904, 2.6047505e-06]\n",
      "batch 25 d_loss : 9.21457391086733e-07\n",
      "batch 25 d_on_g_loss : [3009.7212, 30.097212, 2.6405855e-06]\n",
      "batch 26 d_loss : 9.168841118550447e-07\n",
      "batch 26 d_on_g_loss : [2735.7012, 27.357012, 2.3289576e-06]\n",
      "batch 27 d_loss : 9.081057189380064e-07\n",
      "batch 27 d_on_g_loss : [2831.0454, 28.310453, 2.4756378e-06]\n",
      "batch 28 d_loss : 9.083970947390948e-07\n",
      "batch 28 d_on_g_loss : [2524.0095, 25.240095, 2.4819237e-06]\n",
      "batch 29 d_loss : 9.205565435940085e-07\n",
      "batch 29 d_on_g_loss : [2989.8433, 29.898434, 2.2757631e-06]\n",
      "batch 30 d_loss : 9.080683465375235e-07\n",
      "batch 30 d_on_g_loss : [2706.7656, 27.067656, 2.5119746e-06]\n",
      "batch 31 d_loss : 9.202235134815114e-07\n",
      "batch 31 d_on_g_loss : [2973.2722, 29.732721, 1.5772539e-06]\n",
      "batch 32 d_loss : 9.137540899928353e-07\n",
      "batch 32 d_on_g_loss : [2751.0466, 27.510466, 1.6127644e-06]\n",
      "batch 33 d_loss : 9.048677532408681e-07\n",
      "batch 33 d_on_g_loss : [2850.762, 28.50762, 3.1206819e-06]\n",
      "batch 34 d_loss : 8.945914955534938e-07\n",
      "batch 34 d_on_g_loss : [2455.1184, 24.551184, 2.8393538e-06]\n",
      "batch 35 d_loss : 8.853241212948757e-07\n",
      "batch 35 d_on_g_loss : [2903.1985, 29.031984, 2.0802358e-06]\n",
      "epoch: 6/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 7.608843816342414e-07\n",
      "batch 1 d_on_g_loss : [2429.082, 24.290819, 1.9787822e-06]\n",
      "batch 2 d_loss : 7.766876990444871e-07\n",
      "batch 2 d_on_g_loss : [2846.1616, 28.461617, 2.4316396e-06]\n",
      "batch 3 d_loss : 7.789424633604843e-07\n",
      "batch 3 d_on_g_loss : [2470.2249, 24.702248, 1.5399187e-06]\n",
      "batch 4 d_loss : 7.766823301835757e-07\n",
      "batch 4 d_on_g_loss : [3079.0366, 30.790365, 2.4636502e-06]\n",
      "batch 5 d_loss : 8.091925610642647e-07\n",
      "batch 5 d_on_g_loss : [2852.5559, 28.525558, 1.6875543e-06]\n",
      "batch 6 d_loss : 9.118074293231378e-07\n",
      "batch 6 d_on_g_loss : [3507.0664, 35.070663, 1.906424e-06]\n",
      "batch 7 d_loss : 8.651954463597836e-07\n",
      "batch 7 d_on_g_loss : [2696.4438, 26.964439, 4.0159475e-06]\n",
      "batch 8 d_loss : 8.24362938089962e-07\n",
      "batch 8 d_on_g_loss : [2946.2603, 29.462603, 1.6110525e-06]\n",
      "batch 9 d_loss : 8.028480604278027e-07\n",
      "batch 9 d_on_g_loss : [2676.9888, 26.769888, 2.2903228e-06]\n",
      "batch 10 d_loss : 7.79608692482725e-07\n",
      "batch 10 d_on_g_loss : [2677.3342, 26.773342, 1.5973089e-06]\n",
      "batch 11 d_loss : 7.751996535758239e-07\n",
      "batch 11 d_on_g_loss : [2751.8398, 27.518398, 1.2971775e-06]\n",
      "batch 12 d_loss : 7.696989721731977e-07\n",
      "batch 12 d_on_g_loss : [2766.9395, 27.669394, 2.1345422e-06]\n",
      "batch 13 d_loss : 7.571630878653825e-07\n",
      "batch 13 d_on_g_loss : [2537.3484, 25.373484, 2.3126636e-06]\n",
      "batch 14 d_loss : 7.400601662409047e-07\n",
      "batch 14 d_on_g_loss : [2660.2559, 26.602558, 1.2650146e-06]\n",
      "batch 15 d_loss : 7.307141117962601e-07\n",
      "batch 15 d_on_g_loss : [2447.1018, 24.471018, 1.8352347e-06]\n",
      "batch 16 d_loss : 7.146079976649844e-07\n",
      "batch 16 d_on_g_loss : [2637.7439, 26.377439, 2.0115133e-06]\n",
      "batch 17 d_loss : 7.082367370217338e-07\n",
      "batch 17 d_on_g_loss : [2463.2354, 24.632353, 1.9112342e-06]\n",
      "batch 18 d_loss : 6.969685604948003e-07\n",
      "batch 18 d_on_g_loss : [2637.96, 26.379601, 1.6357861e-06]\n",
      "batch 19 d_loss : 7.162951105424566e-07\n",
      "batch 19 d_on_g_loss : [3440.8406, 34.408405, 1.7717557e-06]\n",
      "batch 20 d_loss : 7.104069018737391e-07\n",
      "batch 20 d_on_g_loss : [3123.0212, 31.230213, 1.5407861e-06]\n",
      "batch 21 d_loss : 7.047249561137072e-07\n",
      "batch 21 d_on_g_loss : [2743.3982, 27.433983, 8.3368093e-07]\n",
      "batch 22 d_loss : 6.933867421242791e-07\n",
      "batch 22 d_on_g_loss : [2743.1941, 27.431942, 1.6618942e-06]\n",
      "batch 23 d_loss : 6.905591365209504e-07\n",
      "batch 23 d_on_g_loss : [2752.0557, 27.520555, 1.4583759e-06]\n",
      "batch 24 d_loss : 6.862190164251084e-07\n",
      "batch 24 d_on_g_loss : [2842.9014, 28.429014, 2.3696439e-06]\n",
      "batch 25 d_loss : 6.857821033463551e-07\n",
      "batch 25 d_on_g_loss : [2811.8838, 28.118837, 1.7382997e-06]\n",
      "batch 26 d_loss : 6.869317830320981e-07\n",
      "batch 26 d_on_g_loss : [2865.9177, 28.659178, 1.6700537e-06]\n",
      "batch 27 d_loss : 6.775402147872632e-07\n",
      "batch 27 d_on_g_loss : [2785.8376, 27.858377, 1.2294067e-06]\n",
      "batch 28 d_loss : 6.680056115117493e-07\n",
      "batch 28 d_on_g_loss : [3198.073, 31.98073, 1.9679053e-06]\n",
      "batch 29 d_loss : 6.61865897004175e-07\n",
      "batch 29 d_on_g_loss : [2958.801, 29.588011, 1.6634366e-06]\n",
      "batch 30 d_loss : 6.60805093464963e-07\n",
      "batch 30 d_on_g_loss : [2365.2158, 23.652159, 2.9819021e-06]\n",
      "batch 31 d_loss : 6.537026064829514e-07\n",
      "batch 31 d_on_g_loss : [2987.1575, 29.871574, 1.3893166e-06]\n",
      "batch 32 d_loss : 6.480788790952374e-07\n",
      "batch 32 d_on_g_loss : [2712.6069, 27.126068, 1.654241e-06]\n",
      "batch 33 d_loss : 6.399816663471221e-07\n",
      "batch 33 d_on_g_loss : [2761.3232, 27.613234, 1.5372539e-06]\n",
      "batch 34 d_loss : 6.365372234326701e-07\n",
      "batch 34 d_on_g_loss : [2754.9194, 27.549194, 1.3853844e-06]\n",
      "batch 35 d_loss : 6.34821204000348e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 35 d_on_g_loss : [2548.4009, 25.484009, 1.4361697e-06]\n",
      "epoch: 7/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 6.402393637472414e-07\n",
      "batch 1 d_on_g_loss : [2746.5938, 27.465937, 1.2454444e-06]\n",
      "batch 2 d_loss : 5.591428902107509e-07\n",
      "batch 2 d_on_g_loss : [2566.1138, 25.661139, 9.2063488e-07]\n",
      "batch 3 d_loss : 5.733944268134413e-07\n",
      "batch 3 d_on_g_loss : [2445.584, 24.455841, 1.3316723e-06]\n",
      "batch 4 d_loss : 5.004842350331274e-07\n",
      "batch 4 d_on_g_loss : [2851.4417, 28.514416, 1.3495935e-06]\n",
      "batch 5 d_loss : 5.012899748635391e-07\n",
      "batch 5 d_on_g_loss : [2737.7952, 27.377951, 2.7917395e-06]\n",
      "batch 6 d_loss : 5.23509784026525e-07\n",
      "batch 6 d_on_g_loss : [3145.9734, 31.459734, 1.5841185e-06]\n",
      "batch 7 d_loss : 5.262112990424482e-07\n",
      "batch 7 d_on_g_loss : [2522.2554, 25.222553, 1.2201297e-06]\n",
      "batch 8 d_loss : 5.194707583200397e-07\n",
      "batch 8 d_on_g_loss : [2792.1902, 27.921902, 1.9913105e-06]\n",
      "batch 9 d_loss : 5.285733373562431e-07\n",
      "batch 9 d_on_g_loss : [2547.928, 25.47928, 1.815177e-06]\n",
      "batch 10 d_loss : 5.521495643279195e-07\n",
      "batch 10 d_on_g_loss : [2987.7986, 29.877987, 1.6197043e-06]\n",
      "batch 11 d_loss : 5.652151788705272e-07\n",
      "batch 11 d_on_g_loss : [3056.8889, 30.56889, 1.3601434e-06]\n",
      "batch 12 d_loss : 5.503853245159007e-07\n",
      "batch 12 d_on_g_loss : [3139.4402, 31.394402, 1.3292681e-06]\n",
      "batch 13 d_loss : 5.385713633971206e-07\n",
      "batch 13 d_on_g_loss : [2952.5979, 29.52598, 1.4602904e-06]\n",
      "batch 14 d_loss : 5.285854298011015e-07\n",
      "batch 14 d_on_g_loss : [2643.7532, 26.437532, 1.273679e-06]\n",
      "batch 15 d_loss : 5.184586632367427e-07\n",
      "batch 15 d_on_g_loss : [2972.8833, 29.728834, 1.2156344e-06]\n",
      "batch 16 d_loss : 5.151296715411036e-07\n",
      "batch 16 d_on_g_loss : [2754.2668, 27.542669, 3.1523111e-06]\n",
      "batch 17 d_loss : 5.103180121616734e-07\n",
      "batch 17 d_on_g_loss : [2724.6985, 27.246984, 1.1024449e-06]\n",
      "batch 18 d_loss : 5.055230126850397e-07\n",
      "batch 18 d_on_g_loss : [2688.7488, 26.887487, 2.1163223e-06]\n",
      "batch 19 d_loss : 5.014057696945728e-07\n",
      "batch 19 d_on_g_loss : [2761.8159, 27.618158, 6.9690816e-07]\n",
      "batch 20 d_loss : 4.944670322970524e-07\n",
      "batch 20 d_on_g_loss : [2657.1389, 26.571388, 1.1340792e-06]\n",
      "batch 21 d_loss : 4.934019922789698e-07\n",
      "batch 21 d_on_g_loss : [2471.1602, 24.711601, 1.5797415e-06]\n",
      "batch 22 d_loss : 4.916711415861838e-07\n",
      "batch 22 d_on_g_loss : [3178.7112, 31.787111, 1.2374021e-06]\n",
      "batch 23 d_loss : 4.851782094924009e-07\n",
      "batch 23 d_on_g_loss : [2714.7622, 27.147623, 1.1146717e-06]\n",
      "batch 24 d_loss : 4.842428900531103e-07\n",
      "batch 24 d_on_g_loss : [2628.2124, 26.282124, 1.230113e-06]\n",
      "batch 25 d_loss : 4.808553148905048e-07\n",
      "batch 25 d_on_g_loss : [2646.2388, 26.462387, 1.3196284e-06]\n",
      "batch 26 d_loss : 4.802802106514019e-07\n",
      "batch 26 d_on_g_loss : [2485.3701, 24.853701, 1.764716e-06]\n",
      "batch 27 d_loss : 4.880180538462069e-07\n",
      "batch 27 d_on_g_loss : [2400.2639, 24.00264, 1.1673719e-06]\n",
      "batch 28 d_loss : 4.898978446021829e-07\n",
      "batch 28 d_on_g_loss : [2703.877, 27.038771, 1.334316e-06]\n",
      "batch 29 d_loss : 4.902136458111209e-07\n",
      "batch 29 d_on_g_loss : [2684.1304, 26.841305, 1.3520954e-06]\n",
      "batch 30 d_loss : 4.866733227496904e-07\n",
      "batch 30 d_on_g_loss : [2276.6833, 22.766832, 1.521177e-06]\n",
      "batch 31 d_loss : 4.828018910713229e-07\n",
      "batch 31 d_on_g_loss : [2383.0647, 23.830647, 9.5277858e-07]\n",
      "batch 32 d_loss : 4.7664426308102745e-07\n",
      "batch 32 d_on_g_loss : [3056.7722, 30.567722, 1.272559e-06]\n",
      "batch 33 d_loss : 4.72011587741387e-07\n",
      "batch 33 d_on_g_loss : [2846.5928, 28.465927, 1.8113036e-06]\n",
      "batch 34 d_loss : 4.7307691555515167e-07\n",
      "batch 34 d_on_g_loss : [2698.0579, 26.980579, 1.1595421e-06]\n",
      "batch 35 d_loss : 4.712677740112018e-07\n",
      "batch 35 d_on_g_loss : [2965.9277, 29.659277, 1.0063414e-06]\n",
      "epoch: 8/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 4.0429046634926633e-07\n",
      "batch 1 d_on_g_loss : [2863.9639, 28.639639, 1.1073357e-06]\n",
      "batch 2 d_loss : 4.4201569551205464e-07\n",
      "batch 2 d_on_g_loss : [3179.2302, 31.792301, 8.280781e-07]\n",
      "batch 3 d_loss : 4.6162298114419776e-07\n",
      "batch 3 d_on_g_loss : [2771.4839, 27.71484, 8.4682193e-07]\n",
      "batch 4 d_loss : 4.665876346621189e-07\n",
      "batch 4 d_on_g_loss : [2506.8359, 25.068359, 1.5321011e-06]\n",
      "batch 5 d_loss : 4.499589601891785e-07\n",
      "batch 5 d_on_g_loss : [2945.5789, 29.455788, 2.6499447e-06]\n",
      "batch 6 d_loss : 4.253023765462179e-07\n",
      "batch 6 d_on_g_loss : [2714.6279, 27.14628, 1.4592528e-06]\n",
      "batch 7 d_loss : 4.223984628229768e-07\n",
      "batch 7 d_on_g_loss : [2451.3513, 24.513514, 9.2515393e-07]\n",
      "batch 8 d_loss : 4.149870306946468e-07\n",
      "batch 8 d_on_g_loss : [2604.158, 26.04158, 1.1141403e-06]\n",
      "batch 9 d_loss : 4.0953574651009857e-07\n",
      "batch 9 d_on_g_loss : [2528.3169, 25.283169, 1.2234739e-06]\n",
      "batch 10 d_loss : 4.363729624401458e-07\n",
      "batch 10 d_on_g_loss : [2923.0054, 29.230053, 9.281116e-07]\n",
      "batch 11 d_loss : 4.291292751449047e-07\n",
      "batch 11 d_on_g_loss : [2534.8442, 25.348442, 9.3031281e-07]\n",
      "batch 12 d_loss : 4.2097999113366314e-07\n",
      "batch 12 d_on_g_loss : [2782.3403, 27.823402, 9.6852705e-07]\n",
      "batch 13 d_loss : 4.0733162642517036e-07\n",
      "batch 13 d_on_g_loss : [2768.321, 27.68321, 1.233546e-06]\n",
      "batch 14 d_loss : 3.984341032849313e-07\n",
      "batch 14 d_on_g_loss : [2468.2317, 24.682318, 1.9002521e-06]\n",
      "batch 15 d_loss : 3.915918622017974e-07\n",
      "batch 15 d_on_g_loss : [3012.823, 30.128231, 7.6904939e-07]\n",
      "batch 16 d_loss : 3.965403244876597e-07\n",
      "batch 16 d_on_g_loss : [3033.2158, 30.332159, 9.1571843e-07]\n",
      "batch 17 d_loss : 3.945482617114869e-07\n",
      "batch 17 d_on_g_loss : [2342.1611, 23.421612, 1.227558e-06]\n",
      "batch 18 d_loss : 3.887134514318152e-07\n",
      "batch 18 d_on_g_loss : [2890.3835, 28.903835, 1.0429881e-06]\n",
      "batch 19 d_loss : 3.89374915393522e-07\n",
      "batch 19 d_on_g_loss : [2815.8862, 28.158861, 8.5507997e-07]\n",
      "batch 20 d_loss : 3.833864590774283e-07\n",
      "batch 20 d_on_g_loss : [2375.1687, 23.751688, 9.5486178e-07]\n",
      "batch 21 d_loss : 3.808965740994435e-07\n",
      "batch 21 d_on_g_loss : [2307.6667, 23.076668, 9.5503128e-07]\n",
      "batch 22 d_loss : 3.795053583065634e-07\n",
      "batch 22 d_on_g_loss : [2655.6711, 26.556711, 9.4527246e-07]\n",
      "batch 23 d_loss : 3.773900793337658e-07\n",
      "batch 23 d_on_g_loss : [2720.6477, 27.206476, 1.0770134e-06]\n",
      "batch 24 d_loss : 3.843832416805526e-07\n",
      "batch 24 d_on_g_loss : [2605.6958, 26.056959, 1.3908466e-06]\n",
      "batch 25 d_loss : 3.842049454760854e-07\n",
      "batch 25 d_on_g_loss : [2581.3179, 25.813179, 1.1267962e-06]\n",
      "batch 26 d_loss : 3.8048164823906586e-07\n",
      "batch 26 d_on_g_loss : [2703.459, 27.03459, 6.3031325e-07]\n",
      "batch 27 d_loss : 3.77727728930579e-07\n",
      "batch 27 d_on_g_loss : [2585.158, 25.85158, 8.8515924e-07]\n",
      "batch 28 d_loss : 3.710483527795207e-07\n",
      "batch 28 d_on_g_loss : [2815.929, 28.15929, 1.2601108e-06]\n",
      "batch 29 d_loss : 3.697724251055504e-07\n",
      "batch 29 d_on_g_loss : [2796.4995, 27.964994, 8.7516304e-07]\n",
      "batch 30 d_loss : 3.6654919332098265e-07\n",
      "batch 30 d_on_g_loss : [2806.5952, 28.065952, 1.3610388e-06]\n",
      "batch 31 d_loss : 3.706291054993105e-07\n",
      "batch 31 d_on_g_loss : [2788.301, 27.883011, 6.3273762e-07]\n",
      "batch 32 d_loss : 3.6708227248993806e-07\n",
      "batch 32 d_on_g_loss : [2737.4585, 27.374586, 1.2481407e-06]\n",
      "batch 33 d_loss : 3.657515742016778e-07\n",
      "batch 33 d_on_g_loss : [2439.5818, 24.395817, 1.1357293e-06]\n",
      "batch 34 d_loss : 3.6386737830900313e-07\n",
      "batch 34 d_on_g_loss : [2535.3787, 25.353786, 8.70755e-07]\n",
      "batch 35 d_loss : 3.627872763445339e-07\n",
      "batch 35 d_on_g_loss : [2723.0269, 27.230268, 8.7032441e-07]\n",
      "epoch: 9/10\n",
      "batches: 35.0\n",
      "batch 1 d_loss : 3.2126849873748143e-07\n",
      "batch 1 d_on_g_loss : [2559.478, 25.59478, 7.1011863e-07]\n",
      "batch 2 d_loss : 3.373683739482658e-07\n",
      "batch 2 d_on_g_loss : [2798.9292, 27.989292, 7.8595497e-07]\n",
      "batch 3 d_loss : 2.9642537147841115e-07\n",
      "batch 3 d_on_g_loss : [2722.4197, 27.224197, 1.012679e-06]\n",
      "batch 4 d_loss : 2.737351167070301e-07\n",
      "batch 4 d_on_g_loss : [2794.4055, 27.944056, 7.7655221e-07]\n",
      "batch 5 d_loss : 3.096617990649975e-07\n",
      "batch 5 d_on_g_loss : [3137.6362, 31.376362, 4.4900833e-07]\n",
      "batch 6 d_loss : 3.0657543277357034e-07\n",
      "batch 6 d_on_g_loss : [2506.3789, 25.063789, 1.0041899e-06]\n",
      "batch 7 d_loss : 3.198929919433015e-07\n",
      "batch 7 d_on_g_loss : [2564.5305, 25.645306, 8.3754071e-07]\n",
      "batch 8 d_loss : 3.246748143226341e-07\n",
      "batch 8 d_on_g_loss : [2508.1477, 25.081478, 8.7064427e-07]\n",
      "batch 9 d_loss : 3.142868649774755e-07\n",
      "batch 9 d_on_g_loss : [2433.0886, 24.330887, 7.0556604e-07]\n",
      "batch 10 d_loss : 3.239523789488885e-07\n",
      "batch 10 d_on_g_loss : [2592.3528, 25.923529, 1.1532776e-06]\n",
      "batch 11 d_loss : 3.254617054567048e-07\n",
      "batch 11 d_on_g_loss : [2909.239, 29.09239, 9.218661e-07]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 12 d_loss : 3.205422961135203e-07\n",
      "batch 12 d_on_g_loss : [2614.3018, 26.143019, 9.9537635e-07]\n",
      "batch 13 d_loss : 3.192425157731822e-07\n",
      "batch 13 d_on_g_loss : [2648.9675, 26.489676, 5.8862906e-07]\n",
      "batch 14 d_loss : 3.188771513253284e-07\n",
      "batch 14 d_on_g_loss : [2476.0574, 24.760574, 1.1602351e-06]\n",
      "batch 15 d_loss : 3.3393117215988847e-07\n",
      "batch 15 d_on_g_loss : [2942.1365, 29.421366, 8.4316173e-07]\n",
      "batch 16 d_loss : 3.268904279707385e-07\n",
      "batch 16 d_on_g_loss : [2411.7854, 24.117855, 9.6563849e-07]\n",
      "batch 17 d_loss : 3.1672417435402165e-07\n",
      "batch 17 d_on_g_loss : [2626.6196, 26.266195, 7.6030057e-07]\n",
      "batch 18 d_loss : 3.116777373672145e-07\n",
      "batch 18 d_on_g_loss : [2917.6152, 29.176153, 1.1180941e-06]\n",
      "batch 19 d_loss : 3.0735210998500406e-07\n",
      "batch 19 d_on_g_loss : [2610.1965, 26.101965, 8.1187426e-07]\n",
      "batch 20 d_loss : 3.105986317564202e-07\n",
      "batch 20 d_on_g_loss : [2623.8457, 26.238457, 1.2112848e-06]\n",
      "batch 21 d_loss : 3.087102037452063e-07\n",
      "batch 21 d_on_g_loss : [2639.03, 26.390301, 1.016271e-06]\n",
      "batch 22 d_loss : 3.061766653383364e-07\n",
      "batch 22 d_on_g_loss : [2566.3325, 25.663324, 7.9383733e-07]\n",
      "batch 23 d_loss : 3.038260909642818e-07\n",
      "batch 23 d_on_g_loss : [2643.9519, 26.439518, 9.4045038e-07]\n",
      "batch 24 d_loss : 3.024256708764976e-07\n",
      "batch 24 d_on_g_loss : [2686.9092, 26.869093, 7.1902952e-07]\n",
      "batch 25 d_loss : 3.018675959083339e-07\n",
      "batch 25 d_on_g_loss : [2711.8806, 27.118807, 6.3453842e-07]\n",
      "batch 26 d_loss : 2.9803256729529985e-07\n",
      "batch 26 d_on_g_loss : [2775.6475, 27.756474, 8.7256564e-07]\n",
      "batch 27 d_loss : 2.9984417406265293e-07\n",
      "batch 27 d_on_g_loss : [2491.3176, 24.913176, 1.0970566e-06]\n",
      "batch 28 d_loss : 2.9582119002010844e-07\n",
      "batch 28 d_on_g_loss : [2689.4963, 26.894962, 8.9818269e-07]\n",
      "batch 29 d_loss : 2.893261243398542e-07\n",
      "batch 29 d_on_g_loss : [2739.7666, 27.397667, 7.808863e-07]\n",
      "batch 30 d_loss : 2.932881835704393e-07\n",
      "batch 30 d_on_g_loss : [2674.196, 26.741961, 4.0117703e-07]\n",
      "batch 31 d_loss : 2.898802875961337e-07\n",
      "batch 31 d_on_g_loss : [2833.4709, 28.334709, 8.346974e-07]\n",
      "batch 32 d_loss : 2.898288752994915e-07\n",
      "batch 32 d_on_g_loss : [2340.4326, 23.404325, 5.4607779e-07]\n",
      "batch 33 d_loss : 2.883273708675915e-07\n",
      "batch 33 d_on_g_loss : [2647.0674, 26.470673, 9.9592285e-07]\n",
      "batch 34 d_loss : 2.874024333971861e-07\n",
      "batch 34 d_on_g_loss : [2864.0955, 28.640955, 6.2430581e-07]\n",
      "batch 35 d_loss : 2.860401718050655e-07\n",
      "batch 35 d_on_g_loss : [2467.0317, 24.670317, 1.324114e-06]\n"
     ]
    }
   ],
   "source": [
    "epoch_num = 10\n",
    "batch_size = 8\n",
    "critic_updates = 5\n",
    "BASE_DIR = 'weights/'\n",
    "x_train = imgs.copy()[:280]\n",
    "y_train = prnus.copy()\n",
    "output_true_batch, output_false_batch = np.ones((batch_size, 1)), np.zeros((batch_size, 1))\n",
    "\n",
    "for epoch in range(epoch_num):\n",
    "    print('epoch: {}/{}'.format(epoch, epoch_num))\n",
    "    print('batches: {}'.format(x_train.shape[0] / batch_size))\n",
    "    \n",
    "    permutated_indexes = np.random.permutation(x_train.shape[0])\n",
    "    \n",
    "    d_losses = []\n",
    "    d_on_g_losses = []\n",
    "    \n",
    "    for index in range(int(x_train.shape[0] / batch_size)):\n",
    "        batch_indexes = permutated_indexes[index*batch_size:(index+1)*batch_size]\n",
    "        image_blur_batch = x_train[batch_indexes]\n",
    "        image_full_batch = y_train[batch_indexes]\n",
    "        \n",
    "        generated_images = g.predict(x=image_blur_batch, batch_size=batch_size)\n",
    "        \n",
    "        for _ in range(critic_updates):\n",
    "            d_loss_real = d.train_on_batch(image_full_batch, output_true_batch)\n",
    "            d_loss_fake = d.train_on_batch(generated_images, output_false_batch)\n",
    "            d_loss = 0.5 * np.add(d_loss_fake, d_loss_real)\n",
    "            d_losses.append(d_loss)\n",
    "        print('batch {} d_loss : {}'.format(index+1, np.mean(d_losses)))\n",
    "        \n",
    "        d.trainable = False\n",
    "        \n",
    "        d_on_g_loss = d_on_g.train_on_batch(image_blur_batch, [image_full_batch, output_true_batch])\n",
    "        d_on_g_losses.append(d_on_g_loss)\n",
    "        print('batch {} d_on_g_loss : {}'.format(index+1, d_on_g_loss))\n",
    "        \n",
    "        d.trainable = True\n",
    "        \n",
    "    with open('log.txt', 'a') as f:\n",
    "        f.write('{} - {} - {}\\n'.format(epoch, np.mean(d_losses), np.mean(d_on_g_losses)))\n",
    "    \n",
    "    save_all_weights(d, g, epoch, int(np.mean(d_on_g_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/PRNU/data/imgs\n"
     ]
    }
   ],
   "source": [
    "cd /home/ubuntu/PRNU/data/imgs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 256, 256, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tt = cv2.imread('Kodak_M1063_34.jpg')\n",
    "x_tt = getFingerprintUtil(np.array([x_tt]))\n",
    "x_tt = np.array([x_tt])\n",
    "x_tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/PRNU/data/weights/713\n"
     ]
    }
   ],
   "source": [
    "cd ../weights/713/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = generator_model()\n",
    "g.load_weights('generator_9_896.h5')\n",
    "generated_images = g.predict(x=x_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('a.npy',generated_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('aa.jpg',generated_images[0]*255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl4cv",
   "language": "python",
   "name": "dl4cv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
